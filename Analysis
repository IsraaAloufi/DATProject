import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from sklearn.decomposition import PCA


def load_data(filepath):
    # Load data from CSV file
    data = pd.read_csv(filepath)
    return data

data = load_data("Wholesale customers data.csv")

def preprocess_data(data):
    # Handle missing values
    data = data.fillna(data.mean())
    # Select relevant columns
    features = data[['Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen']]
    # Standardize features
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)
    return scaled_features

preprocessed_data = preprocess_data(data)

    # Split the dataset into training and testing sets.
def split_data(data, test_size=0.2, random_state=42):
    train_data, test_data = train_test_split(data, test_size=test_size, random_state=random_state)
    return train_data, test_data

train_data, test_data = split_data(preprocessed_data)

# --- Apply K-Means clustering with different numbers of clusters.---
# Evaluate using Silhouette Score and Inertia.

def kmeans_clustering(data, n_clusters):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(data)
    silhouette_avg = silhouette_score(data, labels)
    inertia = kmeans.inertia_
    print(f"Silhouette Score for K-Means (k={n_clusters}): {silhouette_avg}")
    return labels, inertia

for k in range(2, 11):
    labels, inertia = kmeans_clustering(train_data, n_clusters=k)

    # --- Apply DBSCAN clustering with different eps and min_samples values. ---
    # Evaluate using Silhouette Score.


def dbscan_tuning(data, eps_values, min_samples_values, output_file="dbscan_tuning_results.csv"):
    results = []
    for eps in eps_values:
        for min_samples in min_samples_values:
            dbscan = DBSCAN(eps=eps, min_samples=min_samples)
            labels = dbscan.fit_predict(data)
            num_clusters = len(set(labels)) - (1 if -1 in labels else 0)
            num_noise = list(labels).count(-1)
            print(f"DBSCAN (eps={eps}, min_samples={min_samples}): {num_clusters} clusters, {num_noise} noise points")

            if num_clusters > 1:
                silhouette_avg = silhouette_score(data, labels)
                ch_score = calinski_harabasz_score(data, labels)
            else:
                silhouette_avg, ch_score = -1, -1

            results.append({
                "eps": eps,
                "min_samples": min_samples,
                "num_clusters": num_clusters,
                "num_noise": num_noise,
                "silhouette_score": silhouette_avg,
                "calinski_harabasz_score": ch_score
            })

    results_df = pd.DataFrame(results)
    results_df.to_csv(output_file, index=False)
    print(f"DBSCAN tuning results saved to {output_file}")

eps_values = [0.1, 0.2, 0.5]
min_samples_values = [3, 5, 10]
dbscan_results = dbscan_tuning(train_data, eps_values, min_samples_values)

# Visualization:
# Use PCA to reduce dimensionality and visualize clusters.
# Create boxplots for selected features to compare clusters.

def plot_pca_clusters(data, labels):
    pca = PCA(n_components=2)
    reduced_data = pca.fit_transform(data)
    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, cmap='viridis')
    plt.xlabel("PCA Component 1")
    plt.ylabel("PCA Component 2")
    plt.title("PCA of Clusters")
    plt.colorbar(label="Cluster Label")
    plt.show()

def plot_boxplots(data, labels, column):
    data_with_labels = pd.DataFrame(data, columns=["Fresh", "Milk", "Grocery", "Frozen", "Detergents_Paper", "Delicassen"])
    data_with_labels["Cluster"] = labels
    plt.figure(figsize=(10, 6))
    sns.boxplot(x="Cluster", y=column, data=data_with_labels)
    plt.title(f"Boxplot of {column} by Cluster")
    plt.show()

plot_pca_clusters(train_data, labels)
plot_boxplots(train_data, labels, "Fresh")
